services:
  spark-iceberg:
    container_name: spark-iceberg
    build: spark/
    networks:
      datalakehouse_net:
    depends_on:
      - nessie
      - minio
    volumes:
      - ./spark/notebooks:/home/iceberg/notebooks
      - ./spark/data:/home/iceberg/data
      - ./airflow:/root/airflow
    environment:
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
    ports:
      - 8080:8080 # Master Web UI
      - 7077:7077 # Master Port for job submissions
      - 8081:8081 # Worker Web UI
      - 4040-4045:4040-4045 # Additional Spark job UI ports for more jobs
      - 18080:18080 # Spark History Server
      - 8888:8888 # Jupyter Notebook
      - 8090:8090 # Ariflow Webserver Port

  trino:
    image: trinodb/trino:latest
    container_name: trino
    networks:
      datalakehouse_net:
    depends_on:
      - nessie
      - minio
    ports:
      - 8083:8080
    expose:
      - "8083"
    environment:
      - TRINO_NODE_ID=trino
      - TRINO_DATA_DIR=/data
    volumes:
      - ./trino/data:/data
      - ./trino/catalog:/etc/trino/catalog:ro

  nessie:
    image: projectnessie/nessie:latest
    container_name: nessie
    environment:
      - QUARKUS_HTTP_PORT=19120
      - QUARKUS_PROFILE=prod
      - QUARKUS_LOG_CONSOLE_FORMAT=%d{yyyy-MM-dd HH:mm:ss} %-5p [%c{1.}] (%t) %s%e%n
      - QUARKUS_LOG_LEVEL=INFO
      - QUARKUS_DATASOURCE_JDBC_URL=jdbc:postgresql://nessie-db:5432/postgres_db
      - QUARKUS_DATASOURCE_USERNAME=postgres_user
      - QUARKUS_DATASOURCE_PASSWORD=postgres_password
      - NESSIE_VERSION_STORE_TYPE=JDBC
    volumes:
      - ./nessie/nessie_data:/var/lib/nessie/data # Mount local directory to persist nessie data
    ports:
      - "19120:19120" # Expose Nessie API port
    expose:
      - "19120"
    networks:
      datalakehouse_net:
    depends_on:
      - nessie-db

  minio:
    image: minio/minio
    container_name: minio
    environment:
      - MINIO_ROOT_USER=admin
      - MINIO_ROOT_PASSWORD=password
      - MINIO_DOMAIN=minio
      - MINIO_REGION_NAME=us-east-1
      - MINIO_REGION=us-east-1
    volumes:
      - ./minio:/data
    networks:
      datalakehouse_net:
        aliases:
          - warehouse.minio
    ports:
      - 9001:9001
      - 9000:9000
    command: ["server", "/data", "--console-address", ":9001"]

  mc:
    depends_on:
      - minio
    image: minio/mc
    container_name: mc
    networks:
      datalakehouse_net:
    environment:
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
    entrypoint: >
      /bin/sh -c "
      until (/usr/bin/mc config host add minio http://minio:9000 admin password) do echo '...waiting...' && sleep 1; done;
      /usr/bin/mc mb minio/warehouse;
      /usr/bin/mc policy set public minio/warehouse;
      tail -f /dev/null
      "

  kafka:
    image: apache/kafka-native
    ports:
      - "9092:9092"
    expose:
      - "9093"
    networks:
      datalakehouse_net:
    environment:
      # Configure listeners for both docker and host communication
      KAFKA_LISTENERS: CONTROLLER://localhost:9091,HOST://0.0.0.0:9092,DOCKER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: HOST://localhost:9092,DOCKER://kafka:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,DOCKER:PLAINTEXT,HOST:PLAINTEXT

      # Settings required for KRaft mode
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@localhost:9091

      # Listener to use for broker-to-broker communication
      KAFKA_INTER_BROKER_LISTENER_NAME: DOCKER

      # Required for a single node cluster
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  kafka-ui:
    image: ghcr.io/kafbat/kafka-ui:latest
    ports:
      - 9999:8080
    networks:
      datalakehouse_net:
    environment:
      DYNAMIC_CONFIG_ENABLED: "true"
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9093
    depends_on:
      - kafka

  vertica:
    environment:
      APP_DB_USER: "newdbadmin"
      APP_DB_PASSWORD: "vertica"
      TZ: "Europe/Moscow"
    container_name: vertica-ce
    image: vertica/vertica-ce:latest
    ports:
      - "5433:5433"
      - "5444:5444"
    expose:
      - "5433"
    networks:
      datalakehouse_net:
    deploy:
      mode: global
    volumes:
      - type: volume
        source: vertica-data2
        target: /vertica-data2

  nessie-db:
    image: postgres:17
    container_name: nessie-db
    environment:
      POSTGRES_USER: postgres_user
      POSTGRES_PASSWORD: postgres_password
      POSTGRES_DB: postgres_db
      PGDATA: /var/lib/postgresql/data/pgdata
    ports:
      - "5432:5432"
    expose:
      - "5432"
    networks:
      datalakehouse_net:
    volumes:
      - ./postgres/pgdata:/var/lib/postgresql/data/pgdata
    command: >
      postgres -c max_connections=1000
               -c shared_buffers=256MB
               -c effective_cache_size=768MB
               -c maintenance_work_mem=64MB
               -c checkpoint_completion_target=0.7
               -c wal_buffers=16MB
               -c default_statistics_target=100

networks:
  datalakehouse_net:
volumes:
  vertica-data2:
  pgdata:
    driver: local
